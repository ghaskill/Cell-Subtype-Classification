{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n#%matplotlib inline\n#%config InlineBackend.figure_format = 'retina'\n\nfrom pylab import *\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import *\nfrom torch.utils.data import SubsetRandomSampler\nimport matplotlib.pyplot as plt\n\ntorch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T15:41:42.320927Z","iopub.execute_input":"2022-04-18T15:41:42.321475Z","iopub.status.idle":"2022-04-18T15:41:56.618813Z","shell.execute_reply.started":"2022-04-18T15:41:42.321407Z","shell.execute_reply":"2022-04-18T15:41:56.618048Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"PATH = '../input/blood-cells/dataset2-master/dataset2-master/images'\ntransform = transforms.Compose([transforms.Resize((120,120)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = datasets.ImageFolder(PATH + '/TRAIN', transform=transform)\ntest_data = datasets.ImageFolder(PATH + '/TEST', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:41:56.620554Z","iopub.execute_input":"2022-04-18T15:41:56.620961Z","iopub.status.idle":"2022-04-18T15:41:58.75534Z","shell.execute_reply.started":"2022-04-18T15:41:56.620924Z","shell.execute_reply":"2022-04-18T15:41:58.754608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fancy data splitting\n\ndef get_subset(indices, start, end):\n    return indices[start : start + end]\n\n#Define training/validation split for data\nTRAIN_PCT, VALIDATION_PCT = 0.8, 0.2\ntrain_count = int(len(train_data) * TRAIN_PCT)\nvalidation_count = int(len(train_data) * VALIDATION_PCT)\n\nindices = torch.randperm(len(train_data))\n\ntrain_indices = get_subset(indices, 0, train_count)\nvalidation_indices = get_subset(indices, train_count, len(train_data))\n\ndataloaders = {\n    \"train\": torch.utils.data.DataLoader(\n        train_data, sampler=SubsetRandomSampler(train_indices), batch_size = 128\n    ),\n    \"validation\": torch.utils.data.DataLoader(\n        train_data, sampler=SubsetRandomSampler(validation_indices), batch_size = 128\n    ),\n}\n\nprint(len(train_indices))\nprint(len(validation_indices))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:41:58.7566Z","iopub.execute_input":"2022-04-18T15:41:58.756839Z","iopub.status.idle":"2022-04-18T15:41:58.781461Z","shell.execute_reply.started":"2022-04-18T15:41:58.756806Z","shell.execute_reply":"2022-04-18T15:41:58.780775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convolutional Neural Network\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n        self.conv2 = nn.Conv2d(16, 16, 3, 1)\n        self.conv3 = nn.Conv2d(16, 32, 3, 1)\n        self.conv4 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(46656, 4666)\n        self.fc2 = nn.Linear(4666, 128)\n        self.fc3 = nn.Linear(128, 4)\n        self.dropout = nn.Dropout()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = self.conv4(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.fc3(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\nnet = Net().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:41:58.78332Z","iopub.execute_input":"2022-04-18T15:41:58.783581Z","iopub.status.idle":"2022-04-18T15:42:04.50088Z","shell.execute_reply.started":"2022-04-18T15:41:58.783548Z","shell.execute_reply":"2022-04-18T15:42:04.500142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Parameters to tweak:\n- convolution (# layers, filters, etc)\n- dropout (rate, position, # layers)","metadata":{}},{"cell_type":"code","source":"# define loss function and optimizer\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=0.0001)\n#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:42:04.502271Z","iopub.execute_input":"2022-04-18T15:42:04.502535Z","iopub.status.idle":"2022-04-18T15:42:04.508338Z","shell.execute_reply.started":"2022-04-18T15:42:04.502502Z","shell.execute_reply":"2022-04-18T15:42:04.506963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nloss_values = []\nvalid_loss_values = []\ntrain_acc = []\nval_acc = []\n\nfor epoch in range(epochs):  # loop over the dataset multiple times\n    \n    tr_correct = 0\n    tr_total = 0\n    running_loss = 0.0\n    \n    for i, data in enumerate(dataloaders.get('train'), 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        #training loss and accuracy\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        tr_total += labels.size(0)\n        tr_correct += (predicted == labels).sum().item()\n        \n    train_acc.append(100 * tr_correct // tr_total)   \n    loss_values.append(running_loss / train_count)\n    \n    print('TRAINING LOSS: ' + str(loss))\n    print(f'TRAINING ACCURACY: {100 * tr_correct // tr_total} %')\n        \n    correct = 0\n    total = 0\n    running_valid_loss = 0.0\n\n    with torch.no_grad():\n        for data in dataloaders.get('validation'):\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            valid_loss = criterion(outputs, labels)\n            running_valid_loss += valid_loss.item() * images.size(0)\n            \n    val_acc.append(100 * correct // total)\n    valid_loss_values.append(running_valid_loss / validation_count)\n   \n    print('VAL LOSS: ' + str(valid_loss))\n    print(f'VAL ACCURACY: {100 * correct // total} %')\n    print('------------------------------------------------' + str(epoch))\n\ntorch.save(net.state_dict(), '/kaggle/working/WBC_model.pt')\nplt.plot(loss_values, label='train loss')\nplt.plot(valid_loss_values, label='valid loss')\nplt.legend()\nplt.show()\n\nplt.plot(train_acc, label='train acc')\nplt.plot(val_acc, label='valid acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T15:42:04.510083Z","iopub.execute_input":"2022-04-18T15:42:04.510524Z","iopub.status.idle":"2022-04-18T15:44:12.015242Z","shell.execute_reply.started":"2022-04-18T15:42:04.510397Z","shell.execute_reply":"2022-04-18T15:44:12.012655Z"},"trusted":true},"execution_count":null,"outputs":[]}]}